{
  "WhiteSpaceTokenizer": {
    "To jest przykładowy tekst do tokenizacji. Sprawdzimy, jak różne tokenizatory radzą sobie z tym zdaniem. Polska literatura oferuje wiele interesujących dzieł, które warto przeczytać. Czytanie książek rozwija wyobraźnię i poszerza horyzonty myślowe.": {
      "total_tokens": 38,
      "total_words": 32,
      "avg_tokens_per_word": 1.1875,
      "obtained_tokens": [
        "To",
        "jest",
        "<unk>",
        "tekst",
        "do",
        "<unk>",
        ".",
        "<unk>",
        ",",
        "jak",
        "różne",
        "<unk>",
        "<unk>",
        "sobie",
        "z",
        "tym",
        "zdaniem",
        ".",
        "Polska",
        "literatura",
        "oferuje",
        "wiele",
        "interesujących",
        "dzieł",
        ",",
        "które",
        "warto",
        "przeczytać",
        ".",
        "<unk>",
        "książek",
        "rozwija",
        "<unk>",
        "i",
        "<unk>",
        "<unk>",
        "<unk>",
        "."
      ],
      "direct_count": 19,
      "direct_percentage": 59.375
    },
    "Tokenizacja jest kluczowym krokiem w przetwarzaniu języka naturalnego. Różne podejścia mogą prowadzić do różnych wyników. Algorytmy uczenia maszynowego wymagają odpowiedniego przygotowania danych wejściowych. Właściwe przetwarzanie tekstu wpływa na jakość modeli sztucznej inteligencji.": {
      "total_tokens": 36,
      "total_words": 32,
      "avg_tokens_per_word": 1.125,
      "obtained_tokens": [
        "<unk>",
        "jest",
        "kluczowym",
        "krokiem",
        "w",
        "<unk>",
        "języka",
        "naturalnego",
        ".",
        "Różne",
        "podejścia",
        "mogą",
        "prowadzić",
        "do",
        "różnych",
        "wyników",
        ".",
        "<unk>",
        "uczenia",
        "maszynowego",
        "wymagają",
        "odpowiedniego",
        "przygotowania",
        "danych",
        "<unk>",
        ".",
        "<unk>",
        "<unk>",
        "tekstu",
        "wpływa",
        "na",
        "jakość",
        "modeli",
        "sztucznej",
        "inteligencji",
        "."
      ],
      "direct_count": 23,
      "direct_percentage": 71.875
    },
    "W dzisiejszych czasach modele językowe stają się coraz bardziej zaawansowane, a tokenizacja odgrywa ważną rolę w ich skuteczności. Nowoczesne technologie przekształcają sposób, w jaki komunikujemy się i przetwarzamy informacje. Rozwój sztucznej inteligencji otwiera nowe możliwości w wielu dziedzinach nauki.": {
      "total_tokens": 44,
      "total_words": 39,
      "avg_tokens_per_word": 1.1282051282051282,
      "obtained_tokens": [
        "W",
        "dzisiejszych",
        "czasach",
        "modele",
        "językowe",
        "stają",
        "się",
        "coraz",
        "bardziej",
        "zaawansowane",
        ",",
        "a",
        "<unk>",
        "odgrywa",
        "ważną",
        "rolę",
        "w",
        "ich",
        "skuteczności",
        ".",
        "<unk>",
        "technologie",
        "<unk>",
        "sposób",
        ",",
        "w",
        "jaki",
        "<unk>",
        "się",
        "i",
        "<unk>",
        "informacje",
        ".",
        "Rozwój",
        "sztucznej",
        "inteligencji",
        "otwiera",
        "nowe",
        "możliwości",
        "w",
        "wielu",
        "dziedzinach",
        "nauki",
        "."
      ],
      "direct_count": 29,
      "direct_percentage": 74.35897435897436
    }
  },
  "SentencePieceTokenizer": {
    "To jest przykładowy tekst do tokenizacji. Sprawdzimy, jak różne tokenizatory radzą sobie z tym zdaniem. Polska literatura oferuje wiele interesujących dzieł, które warto przeczytać. Czytanie książek rozwija wyobraźnię i poszerza horyzonty myślowe.": {
      "total_tokens": 55,
      "total_words": 32,
      "avg_tokens_per_word": 1.71875,
      "obtained_tokens": [
        "To",
        "jest",
        "przykład",
        "owy",
        "tekst",
        "do",
        "to",
        "ken",
        "izacji",
        ".",
        "Spraw",
        "dzi",
        "my",
        ",",
        "jak",
        "różne",
        "to",
        "ken",
        "iz",
        "atory",
        "rad",
        "zą",
        "sobie",
        "z",
        "tym",
        "zdaniem",
        ".",
        "Polska",
        "literatura",
        "oferuje",
        "wiele",
        "interesując",
        "ych",
        "dzieł",
        ",",
        "które",
        "warto",
        "prze",
        "czyt",
        "ać",
        ".",
        "Czy",
        "ta",
        "nie",
        "książek",
        "rozwija",
        "wyobraźni",
        "ę",
        "i",
        "poszerza",
        "horyzont",
        "y",
        "myśl",
        "owe",
        "."
      ],
      "direct_count": 19,
      "direct_percentage": 59.375
    },
    "Tokenizacja jest kluczowym krokiem w przetwarzaniu języka naturalnego. Różne podejścia mogą prowadzić do różnych wyników. Algorytmy uczenia maszynowego wymagają odpowiedniego przygotowania danych wejściowych. Właściwe przetwarzanie tekstu wpływa na jakość modeli sztucznej inteligencji.": {
      "total_tokens": 49,
      "total_words": 32,
      "avg_tokens_per_word": 1.53125,
      "obtained_tokens": [
        "To",
        "ken",
        "izacja",
        "jest",
        "klucz",
        "owym",
        "krokiem",
        "w",
        "przetwarza",
        "niu",
        "języka",
        "naturalnego",
        ".",
        "Róż",
        "ne",
        "podejścia",
        "mogą",
        "prowadzić",
        "do",
        "różnych",
        "wyników",
        ".",
        "Algorytm",
        "y",
        "uczeni",
        "a",
        "maszynowego",
        "wymagają",
        "odpowiedniego",
        "przygotowania",
        "danych",
        "wejściowy",
        "ch",
        ".",
        "W",
        "ła",
        "ści",
        "we",
        "przetwarza",
        "nie",
        "tekstu",
        "wpływa",
        "na",
        "jakość",
        "modeli",
        "sztuczn",
        "ej",
        "inteligencji",
        "."
      ],
      "direct_count": 19,
      "direct_percentage": 59.375
    },
    "W dzisiejszych czasach modele językowe stają się coraz bardziej zaawansowane, a tokenizacja odgrywa ważną rolę w ich skuteczności. Nowoczesne technologie przekształcają sposób, w jaki komunikujemy się i przetwarzamy informacje. Rozwój sztucznej inteligencji otwiera nowe możliwości w wielu dziedzinach nauki.": {
      "total_tokens": 54,
      "total_words": 39,
      "avg_tokens_per_word": 1.3846153846153846,
      "obtained_tokens": [
        "W",
        "dzisiejszych",
        "czasach",
        "modele",
        "język",
        "owe",
        "stają",
        "się",
        "coraz",
        "bardziej",
        "zaawansowane",
        ",",
        "a",
        "to",
        "ken",
        "izacja",
        "odgrywa",
        "ważną",
        "rolę",
        "w",
        "ich",
        "skuteczności",
        ".",
        "Nowo",
        "czesne",
        "technolog",
        "ie",
        "przekształca",
        "ją",
        "sposób",
        ",",
        "w",
        "jaki",
        "komuni",
        "k",
        "ujemy",
        "się",
        "i",
        "przetwarza",
        "my",
        "informacje",
        ".",
        "Rozwój",
        "sztuczn",
        "ej",
        "inteligencji",
        "otwiera",
        "nowe",
        "możliwości",
        "w",
        "wielu",
        "dziedzinach",
        "nauki",
        "."
      ],
      "direct_count": 26,
      "direct_percentage": 66.66666666666666
    }
  },
  "LlamaTokenizerFast": {
    "To jest przykładowy tekst do tokenizacji. Sprawdzimy, jak różne tokenizatory radzą sobie z tym zdaniem. Polska literatura oferuje wiele interesujących dzieł, które warto przeczytać. Czytanie książek rozwija wyobraźnię i poszerza horyzonty myślowe.": {
      "total_tokens": 50,
      "total_words": 32,
      "avg_tokens_per_word": 1.5625,
      "obtained_tokens": [
        "▁To",
        "▁jest",
        "▁przykład",
        "owy",
        "▁tekst",
        "▁do",
        "▁to",
        "ke",
        "nizacji",
        ".",
        "▁Spraw",
        "dzimy",
        ",",
        "▁jak",
        "▁różne",
        "▁to",
        "ke",
        "niz",
        "atory",
        "▁radzą",
        "▁sobie",
        "▁z",
        "▁tym",
        "▁zdaniem",
        ".",
        "▁Polska",
        "▁literatura",
        "▁oferuje",
        "▁wiele",
        "▁interesujących",
        "▁dzieł",
        ",",
        "▁które",
        "▁warto",
        "▁przeczytać",
        ".",
        "▁Czy",
        "tanie",
        "▁książek",
        "▁rozwija",
        "▁wyobraźnię",
        "▁i",
        "▁posze",
        "rza",
        "▁horyzon",
        "ty",
        "▁myśl",
        "owe",
        "."
      ],
      "direct_count": 21,
      "direct_percentage": 65.625
    },
    "Tokenizacja jest kluczowym krokiem w przetwarzaniu języka naturalnego. Różne podejścia mogą prowadzić do różnych wyników. Algorytmy uczenia maszynowego wymagają odpowiedniego przygotowania danych wejściowych. Właściwe przetwarzanie tekstu wpływa na jakość modeli sztucznej inteligencji.": {
      "total_tokens": 45,
      "total_words": 32,
      "avg_tokens_per_word": 1.40625,
      "obtained_tokens": [
        "▁To",
        "ke",
        "nizacja",
        "▁jest",
        "▁kluczowym",
        "▁krokiem",
        "▁w",
        "▁przetwarza",
        "niu",
        "▁języka",
        "▁naturalnego",
        ".",
        "▁Różne",
        "▁podejścia",
        "▁mogą",
        "▁prowadzić",
        "▁do",
        "▁różnych",
        "▁wyników",
        ".",
        "▁Al",
        "goryt",
        "my",
        "▁uczenia",
        "▁maszyn",
        "owego",
        "▁wymagają",
        "▁odpowiedniego",
        "▁przygotowania",
        "▁danych",
        "▁wejści",
        "owych",
        ".",
        "▁Właści",
        "we",
        "▁przetwarzanie",
        "▁tekstu",
        "▁wpływa",
        "▁na",
        "▁jakość",
        "▁modeli",
        "▁sztucznej",
        "▁inteligencji",
        "."
      ],
      "direct_count": 23,
      "direct_percentage": 71.875
    },
    "W dzisiejszych czasach modele językowe stają się coraz bardziej zaawansowane, a tokenizacja odgrywa ważną rolę w ich skuteczności. Nowoczesne technologie przekształcają sposób, w jaki komunikujemy się i przetwarzamy informacje. Rozwój sztucznej inteligencji otwiera nowe możliwości w wielu dziedzinach nauki.": {
      "total_tokens": 53,
      "total_words": 39,
      "avg_tokens_per_word": 1.358974358974359,
      "obtained_tokens": [
        "▁W",
        "▁dzisiejszych",
        "▁czasach",
        "▁modele",
        "▁języ",
        "kowe",
        "▁stają",
        "▁się",
        "▁coraz",
        "▁bardziej",
        "▁zaawansowane",
        ",",
        "▁a",
        "▁to",
        "ke",
        "nizacja",
        "▁odgrywa",
        "▁ważną",
        "▁rolę",
        "▁w",
        "▁ich",
        "▁skuteczności",
        ".",
        "▁Nowoczes",
        "ne",
        "▁technologie",
        "▁przekształ",
        "cają",
        "▁sposób",
        ",",
        "▁w",
        "▁jaki",
        "▁komu",
        "niku",
        "jemy",
        "▁się",
        "▁i",
        "▁przetwarza",
        "my",
        "▁informacje",
        ".",
        "▁Rozwój",
        "▁sztucznej",
        "▁inteligencji",
        "▁otwiera",
        "▁nowe",
        "▁możliwości",
        "▁w",
        "▁wielu",
        "▁dziedzinach",
        "▁nauki",
        "."
      ],
      "direct_count": 28,
      "direct_percentage": 71.7948717948718
    }
  }
}