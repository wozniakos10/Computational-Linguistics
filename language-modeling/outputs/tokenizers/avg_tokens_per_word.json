{
  "WhiteSpaceTokenizer": {
    "total_tokens": 2799215,
    "total_words": 2348198,
    "avg_tokens_per_word": 1.1920694081163514
  },
  "SentencePieceTokenizer": {
    "total_tokens": 3650154,
    "total_words": 2348198,
    "avg_tokens_per_word": 1.5544489859884048
  },
  "LlamaTokenizerFast": {
    "total_tokens": 4515875,
    "total_words": 2348198,
    "avg_tokens_per_word": 1.923123603716552
  }
}